# 데이터의 기본 특성
## 범주형 변수의 빈도수, 상대도수 구하기
### 절대빈도수 구하기
library(MASS)
data <- data.frame(Cars93)
data
str(data)
summary(data)
table(data$Manufacturer)
### 상대도수 구하기 : prop.table()
prop.table(summary(data$Manufacturer))
prop.table(table(data$Manufacturer))
prop.table(table(data$Manufacturer)) * 100
round(prop.table(table(data$Manufacturer)) * 100, 2)
paste0(round(prop.table(table(data$Manufacturer)) * 100, 2), '%')
paste0('(', round(prop.table(table(data$Manufacturer)) * 100, 2), '%)')
### 테이블 형태로 표현
data.frame('Freq' = table(data$Manufacturer),
'Prop' = paste0(round(prop.table(table(data$Manufacturer)) * 100, 2), '%'))
## 연속형 변수의 평균, 표준편차 구하기
### summary() : 기초 통계량
mean(data$Price)
sd(data$Price)
paste(round(mean(data$Price), 1), '', round(sd(data$Price), 1))
paste(round(mean(data$Price), 1), '＋', round(sd(data$Price), 1))
paste(round(mean(data$Price), 1), '±', round(sd(data$Price), 1))
## 기술통계 분석에 유용한 함수
install.packages('moonBook')
library(moonBook)
mytable(daya)
mytable(data)
library(foreign)
row <- read.spss('C:/K_digital/data/HN21_ALL(SPSS)/HN21_ALL.sav')
row <- read.spss('C:/K_digital/data/HN21_ALL(SPSS)/HN21_ALL.sav', to.data.frame = T)
View(row)
dat <- read.spss('C:/K_digital/data/test3.sav')
dat
View(dat)
View(dat)
dat <- read.spss('C:/K_digital/data/test3.sav', to.data.frame = T)
View(dat)
dat <- read.spss('C:/K_digital/data/test3.sav', to.data.frame = T, reencode = 'utf-8')
# 방대한 데이터의 형태를 파악하는 패키지
install.packages('Data')
# 방대한 데이터의 형태를 파악하는 패키지
install.packages('DataExplorer')
library(DataExplorer)
introduce(row)
# 변수별 결측률 확인
profile_missing(row)
# 변수별 결측률 확인
row_missing <- profile_missing(row)
# 결측률이 90% 이상인 데이터만 추출
arragne(row_missing, desc(pct_missing))
# 결측률이 90% 이상인 데이터만 추출
arrange(row_missing, desc(pct_missing))
subset(row_missing, pct_missing > 0.9)
library(dplyr)
arrange(subset(row_missing, pct_missing > 0.9), desc(pct_missing))
istall.describe(data)
istall.packages('psych')
pstch::describe(data)
psych::describe(data)
names(row)
df <- read.spss('C:/K_digital/data/HN18_ALL(SPSS)/HN18_ALL.sav', to.data.frame = T, reencode = 'UTF-8')
names(df)
## 추출할 변수 : id, 성별, 나이, 당뇨병 유무(19세 이상), 인슐린 주사, 공복혈당, 당화혈색소
vars <- c('ID', 'sex', 'age', 'HE_DM', 'DE1_31', 'HE_glu', 'HE_HbA1c')
vars
data_f <- select(df, vars)
vars
# 데이터 확인
head(data_f, 10)
# 변수별 결측치 확인
introduce(data_f)
# 결측치 제거 : na.omit() - 결측이 존재하는 행을 제거하는 함수
data_f <- na.omit(data_f)
head(data_f, 10)
table(data_f$HE_DM)
data_f$HE_DM2 <- ifelse(data_f$HE_DM == 3, 1, 0)
# 인슐린 투여 DE1_31
## 0(아니오), 1(예), 8(비해당), 9(모름)
## 필요대상 추출
data_subj <- subset(data_f, data_f$HE_DM2 == 1 & data_f$DE1_31 == 0 | data_f$DE1_31 == 1)
data_subj
## 최종 추출 대상자수
nrow(data_subj)
## 데이터 확인
head(data_subj, 10)
# t검정 수행시 사전에 정규성을 띄고 있어야 한다는 전제 조건
## 시각적인 방법(히스토그램)과 통계량을 이용하는 방법
### histogram
hist(data_subj)
# t검정 수행시 사전에 정규성을 띄고 있어야 한다는 전제 조건
## 시각적인 방법(히스토그램)과 통계량을 이용하는 방법
### histogram
hist(data_subj$HE_glu)
# t검정 수행시 사전에 정규성을 띄고 있어야 한다는 전제 조건
## 시각적인 방법(히스토그램)과 통계량을 이용하는 방법
### histogram
hist(data_subj$HE_glu, freq = F, ylim = (0, 0.05))
# t검정 수행시 사전에 정규성을 띄고 있어야 한다는 전제 조건
## 시각적인 방법(히스토그램)과 통계량을 이용하는 방법
### histogram
hist(data_subj$HE_glu, freq = F, ylim = c(0, 0.05), xlab = 'He_glu(공복혈당)')
# t검정 수행시 사전에 정규성을 띄고 있어야 한다는 전제 조건
## 시각적인 방법(히스토그램)과 통계량을 이용하는 방법
### histogram
hist(data_subj$HE_glu, freq = F, ylim = c(0, 0.03), xlab = 'He_glu(공복혈당)')
# t검정 수행시 사전에 정규성을 띄고 있어야 한다는 전제 조건
## 시각적인 방법(히스토그램)과 통계량을 이용하는 방법
### histogram
hist(data_subj$HE_glu, freq = F, ylim = c(0, 0.02), xlab = 'He_glu(공복혈당)')
# t검정 수행시 사전에 정규성을 띄고 있어야 한다는 전제 조건
## 시각적인 방법(히스토그램)과 통계량을 이용하는 방법
### histogram
hist(data_subj$HE_glu, freq = F, ylim = c(0, 0.015), xlab = 'He_glu(공복혈당)')
# t검정 수행시 사전에 정규성을 띄고 있어야 한다는 전제 조건
## 시각적인 방법(히스토그램)과 통계량을 이용하는 방법
### histogram
hist(data_subj$HE_glu, freq = F, ylim = c(0, 0.02), xlab = 'He_glu(공복혈당)')
### kernel density plot
lines(density(data_subj$HE_glu), col = 'blue')
### kernel density plot
lines(density(data_subj$HE_glu), col = 'blue', lwd = 2)
# Q-Q plot
qqnorm(data_subj$HE_glu)
# Q-Q plot
qqnorm(data_subj$HE_glu, col = 'gray')
qqline(data_subj$HE_glu, col = 'red')
qqline(data_subj$HE_glu, col = 'red', lwd = 2)
### Shapiro-Wilk test : 정규성 검정
#### 귀무가설(H0) : 정규분포를 따른다.
#### 대립가설(H1, 연구가설, 나의가설) : 정규분포를 따르지 않는다.
shapiro.test(data_subj$HE_glu)
### Kolmogorov-Smirnov test
ks.test(data_subj$HE_glu, y = 'pnorm', alternative = 'two.sided')
?ks.test
# 등분산성 검정
## 귀무가설 : 두 그룹의 분산은 차이가 없다.
## 대립가설 : 두 그룹의 분산은 차이가 있다.
var.test(data_subj$HE_glu ~ data_subj$DE1_31)
# 데이터 분석 결과
## 정규분포를 따르지 않고, 인슐린 투여 그룹 간 분산이 달랐다.
t.test(data_subj$HE_glu ~ data_subj$DE1_31, paired = F, var.equal = F)
# 데이터 분석 결과
## 정규분포를 따르지 않고, 인슐린 투여 그룹 간 분산이 달랐다.
### paired = F 독립표본 t검정을 수행
t.test(data_subj$HE_glu ~ data_subj$DE1_31, paired = F, var.equal = F, conf.level = 0.95)
# 일원배치 분산분석(one-way ANOVA)
## 세 개 이상의 집단간의 평균의 차이가 통계적으로 유의미한지 비교할 때 사용
## 가정 : 정규성, 등분산성, 독립성
### 귀무가설 : 모든 모집단의 평균은 동일하다.
### 대립가설 : 모든 모집단의 평균은 동일하지 않다.
study <- read.csv('C:/K_digital/data/ANOVA 예제.csv')
# 일원배치 분산분석(one-way ANOVA)
## 세 개 이상의 집단간의 평균의 차이가 통계적으로 유의미한지 비교할 때 사용
## 가정 : 정규성, 등분산성, 독립성
### 귀무가설 : 모든 모집단의 평균은 동일하다.
### 대립가설 : 모든 모집단의 평균은 동일하지 않다.
study <- read.csv('C:/K_digital/data/ANOVA 예제.csv', header = T)
study
## 정규성 확인
shapiro.test(subset(study, group == 'A')$time)
shapiro.test(subset(study, group == 'B')$time)
shapiro.test(subset(study, group == 'C')$time)
shapiro.test(study[study, group == 'B', time])
shapiro.test(study[study$group == 'B', time])
shapiro.test(study[study$group == 'B', 'time'])
shapiro.test(study[study$group == 'C', ]$time)
## 등분산성 확인
install.packages('lawstat')
library(lawstat)
levene.test(study$time)
levene.test(study$time, study$group, location = "mean")
## ANOVA
reslut <- aov(time ~ group, data = study)
## ANOVA
result <- aov(time ~ group, data = study)
result
summary(result)
data(Boston)
# 해당 데이터셋을 파일로 저장
write.csv(Boston, file = 'boston.csv', row.names = T)
df <- read.csv('boston.csv', header = T, stringsAsFactors = F)
df
# 종속변수에 해당하는 medv(집값)을 제외하고 데이터 추출
df <- df[, -1]
df
# 기술통계량
install.packages('Hmisc')
library(Hmisc)
describe(df)
summart(medv ~ crim + zn, data = df)
summary(medv ~ crim + zn, data = df)
# 데이터 전처리
## 결측치 확인
sum(is.na(df))
df[complete.cases(df), ]
head(df, 10)
# 결측치 삭제
df <- na.omit(df)
# 결측치 대체
df$crim[in.na(df$crim)]
# 결측치 대체
df$crim[in.na(df$crim)] -> 0
install.packages('DMwR')
library(DMwR)
mean_crim <-  mean(df$crim)
# 데이터 분할 - 학습, 성능평가
nrow(df)
## 랜덤 샘플링 : train(70%), test(30%)
df_idx <- sample(1:506, 300)
df_train <- df[df_idx, ]
df_test <- df[-df_idx, ]
nrow(df_train)
nrow(df_test)
# 다중회귀분석
result <- lm(medv ~ ., data = df_train)
result
summary(result)
## 다중공선성 : 독립변수들간에 지나친 상관관계가 존재
### 팽창지수(vif)
install.packages('car')
library(car)
vif(result)
# 상관관계 - 시각화, 통계량(cor)
plot(df_train)
# 이상치 분석
outlierTest(result)
model <- lm(medv ~ ., df_train)
model2 <- step(model, direction = 'both')
# AIC : 통계 모델 간의 적합성을 비교하는 모델 지표
# AIC는 작을수록 더 좋은 모델을 의미한다.
model3 <- lm(medv ~ crim + zn + chas + nox + rm + dis + rad + tax + ptratio + black + lstat, df_train)
summary(model3)
df_test <- df_test[,-15]
expect <- predict(model2, newdata=df_test)
df_test <- df[-df_idx,]
actual <- df_test$medv
result_df <- data.frame(actual, expect)
result_df
t.test(result_df)
install.packages("httr") # HTTP통신을 위한 패키지 설치
library(httr)
GET('http://apis.data.go.kr/B551177/StatusOfArrivals/getArrivalsCongestion?serviceKey=서비스키&numOfRows=10&pageNo=1&terno=T1&airport=HAN&type=xml')
get
